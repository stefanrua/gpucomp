<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Exploration of GPU-enabled lossless compressors</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Exploration of GPU-enabled lossless compressors</h1>
</header>
<p><strong>Stefan Rua</strong><br />
<code>stefan.rua@iki.fi</code><br />
<br />
<strong>Andrea Bocci</strong><br />
<code>andrea.bocci@cern.ch</code><br />
<br />
<br />
</p>
<p>We present the results of a study on the use of GPUs for data compression, using collision data collected by the CMS experiment as a case study.</p>
<h2 id="introduction">Introduction</h2>
<!--
The Compact Muon Solenoid (CMS) is a detector and an experiment at CERN. It gathers data on collisions taking place in the Large Hadron Collider (LHC). Not all of the data contains interesting events, and it goes through multiple levels of triggers where most of it is discarded. The last trigger is the High Level Trigger (HLT), from which the data is sent to datacenters away from the detector. In order to speed up the network transfers between the HLT and datacenters, the data is compressed.
-->
<p>The Large Hadron Collider (LHC) at CERN can accelerate and collide protons or heavier ions, usually lead nuclei. The Compact Muon Solenoid (CMS) experiment uses a complex detector to analyse the particles produced in these collisions. As the LHC can generate collisions up to 40 MHz, which would result in too much data to be read out and stored for offline processing, CMS uses a trigger system with two level to select only the most interesting collision events: the first level, called Level-1 Trigger, uses FPGAs and dedicated electronics to reduce the data rate to a maximum of 100 kHz; the last level, call High Level Trigger (HLT), runs a streamlined version of the CMS reconstruction software (CMSSW) on a computer farm to further reduce the data rate to an average of a few kHz; from the beginning of Run-3 in 2022 the HLT farm has been equipped with GPUs. The data selected by the HLT is transferred to the Tier-0 datacentre in the CERN campus for storage and further processing. In order to speed up the data aggregation inside the HLT and the network transfers between the HLT and Tier-0, the data is compressed.</p>
<h2 id="motivation">Motivation</h2>
<!--
Currently the data is compressed using CPUs which are used for other workloads as well. The machines at the HLT are equipped with GPUs, so it would be good to reduce CPU time taken by the compression workload by transferring it onto the GPUs.
-->
<p>Currently the data are compressed using CPUs; as the HLT machines are equipped with GPUs, we investigate the possibility of offloading the data compression to GPUs, to free up the CPUs for performing other tasks. We also investigate the performance of the NX on-chip data compression accelerator integrated in the IBM POWER9 processors; while such machines are not used at HLT, they are used at HPC sites that run the CMS reconstruction software.</p>
<h2 id="benchmarking">Benchmarking</h2>
<p>We implemented the compressors into a benchmarking program called <code>lzbench</code><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. When possible, compressors are compiled with the same compiler options to achieve the fairest possible comparison. <code>lzbench</code> runs the compression in memory, meaning that disk reads and writes are excluded. The benchmarks were run on two machines: one with a configuration similar to the machines in the HLT farm, and a POWER9 machine.</p>
<h3 id="hlt-like-machine">HLT-like machine</h3>
<p>This machine is equipped with two AMD EPYC “Milan” 75F3 CPUs<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> and two NVIDIA T4 GPUs<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>:</p>
<ul>
<li>AMD EPYC 75F3
<ul>
<li>32 cores</li>
<li>2.95 GHz base / 4.0 GHz boost clock</li>
<li>256 MB L3 cache</li>
</ul></li>
<li>NVIDIA Tesla T4
<ul>
<li>2560 CUDA cores</li>
<li>585 MHz base / 1590 MHz boost clock</li>
<li>16 GB GDDR6</li>
</ul></li>
</ul>
<h3 id="power9-machine">POWER9 machine</h3>
<p>This machine has an IBM POWER9 CPU<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> and four NVIDIA V100 GPUs<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>:</p>
<ul>
<li>8335-GTH / IBM Power System AC922</li>
<li>IBM POWER9
<ul>
<li>32 cores</li>
<li>max. 4 GHz</li>
<li>320 MB L3 cache</li>
</ul></li>
<li>4 x NVIDIA Tesla V100
<ul>
<li>5120 CUDA cores</li>
<li>1530 MHz boost clock</li>
<li>32 GB HBM2</li>
</ul></li>
</ul>
<h2 id="compressors">Compressors</h2>
<!--
| Name | Description |
|:---|:---|
| `bsc`[^bsc] | **B**lock-**s**orting **c**ompressor by Ilya Grebnov. |
| `dietgpu`[^dietgpu] | Asymmetric numeral systems (ANS)[^ans] implementation by Facebook. |
| `libxz`[^libnxz]^,^[^libnxz_git] | IBM's POWER9 processors have a hardware accelerator, NX, for `gzip`. `libnxz` is the library for compressing on it. |
| `nvcomp`[^nvcomp]^,^[^nvcomp_git] | Compression library by NVIDIA, unfortunately made proprietary in version 2.3. |
-->
<p>As a starting point, we have measured the performance of the lossless data compressors that can be used natively in CMSSW, runing only on CPU:</p>
<ul>
<li><strong>LZ4</strong><a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a><br />
lz4 is a compression algorithm that prioritizes speed, based on the LZ77 dictionary compression.<br />
</li>
<li><strong>zlib</strong><a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a><br />
<code>zlib</code> is a compression library that implements the DEFLATE algorithm; it combines a dictionary-matching stage based on LZ77 and a Huffman entropy coding stage.<br />
</li>
<li><strong>LZMA</strong><a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a><br />
the Lempel–Ziv–Markov chain algorithm is an algorithm that prioritizes compression ratio over speed, using a variant of the LZ77 dictionary compression algorithm followed by a probability-based range encoder.<br />
</li>
<li><strong>Zstandard</strong><a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a><br />
Zstandard is a fast compression algorithm providing high compression ratios; it combines a dictionary-matching stage based on LZ77 with a large search window and a fast entropy-coding stage, using both Huffman coding and a fast tabled version of Asymmetric Numeral Systems<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> (ANS).<br />
</li>
</ul>
<p>We then explored the most promising compressors that can offload at least part of their computation to GPUs:</p>
<ul>
<li><strong>bsc</strong><a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a><br />
The Block-Sorting Compressor by Ilya Grebnov.<br />
</li>
<li><strong>dietgpu</strong><a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a><br />
A GPU implementation of the Asymmetric Numeral Systems<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> (ANS) being developed at Facebook.<br />
</li>
<li><strong>nvcomp</strong><a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a><br />
A GPU compression library developed by NVIDIA, unfortunately made proprietary in version 2.3. We tested the earlier open source version which was already in <code>lzbench</code>.</li>
</ul>
<p>Finally, we benchmarked the POWER9 NX compression hardware using <code>libnxz</code>: - <strong>libnxz</strong><a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a><br />
libnxz implements a <code>zlib</code>-compatible API for Linux userspace programs that exploit the NX accelerator available on POWER9 and newer processors.<br />
</p>
<!--
- `bsc`[^bsc] \
**B**lock-**s**orting **c**ompressor by Ilya Grebnov. \
- `dietgpu`[^dietgpu] \
Asymmetric numeral systems (ANS)[^ans] implementation by Facebook. \
- `libxz`[^libnxz]^,^[^libnxz_git] \
IBM's POWER9 processors have a hardware accelerator, NX, for `gzip`. `libnxz` is the library for compressing on it. \
- `nvcomp`[^nvcomp]^,^[^nvcomp_git] \
Compression library by NVIDIA, unfortunately made proprietary in version 2.3.


[^bsc]: <https://github.com/IlyaGrebnov/libbsc>
[^ans]: <https://arxiv.org/pdf/1311.2540.pdf>
[^dietgpu]: <https://github.com/facebookresearch/dietgpu>
[^libnxz]: <https://dl.acm.org/doi/pdf/10.1109/ISCA45697.2020.00012>
[^libnxz_git]: <https://github.com/libnxz/power-gzip>
[^nvcomp]: <https://developer.nvidia.com/nvcomp>
[^nvcomp_git]: <https://github.com/NVIDIA/nvcomp>
-->
<h2 id="input-samples-and-results">Input samples and results</h2>
<p>Two types of collisions take place at the LHC: proton-proton and heavy ion collisions. We ran the benchmarks on both types of data. In the benchmarks these events have been compressed individually, rather than as a batch, to replicate the approach used by the HLT where the events are compressed individually to ease their aggregation.</p>
<h3 id="proton-proton-events-sample">Proton-proton events sample</h3>
<p>The first set of measurements were performed using 100 events from proton-proton collisions collected on August 11th, 2022 with an average pileup of 50 collisions per event. Their uncompressed size ranges between 1.4 MB and 2.1 MB, with an average of 1.7 MB per event.</p>
<!--
- HadronsTaus stream from 2022
- pileup $\approx$ 50
- 100 files
- 170 MB
- 1 event per file
- 1.4 MB to 2.1 MB each
-->
<h3 id="proton-proton-events-compression-results">Proton-proton events compression results</h3>
<p><img src="results/hlt-pp.png" /></p>
<p><img src="results/p9-pp.png" /></p>
<h3 id="heavy-ion-events-sample">Heavy ion events sample</h3>
<p>The second set of measurements were performed using 100 events from lead-lead collisions collected on November 25th, 2018. Their uncompressed size ranges between 640 kB and 5.5 MB, with an average of 1.3 MB per event.</p>
<!--
- from 2018
- 100 files
- 131 MB
- 1 event per file
- 644 KB to 5.5 MB each
-->
<h3 id="heavy-ion-events-compression-results">Heavy ion events compression results</h3>
<p><img src="results/hlt-hi.png" /></p>
<p><img src="results/p9-hi.png" /></p>
<!--
## Timing

- Wall time
- Disk $\rightarrow$ RAM **excluded**
- RAM $\rightarrow$ GPU memory **included**
- Fastest from 5 repeats
-->
<!--
## Results

![](results/hlt-pp.png)

![](results/p9-pp.png)

![](results/hlt-hi.png)

![](results/p9-hi.png)

## First simple tests

Note: these were simply run from the command line and timed using the `time` command, so copying from disk to RAM and back is included.

![](results/first.png){ width=80% }
-->
<h2 id="conclusion-and-future-work">Conclusion and future work</h2>
<p>Using the CPU compressor <code>zstd</code> is a reasonable choice with our current hardware and the current state of GPU compressors. <code>dietgpu</code> is promising, and may see significant improvements in the future, as it is in a very early stage in development. <code>dietgpu</code> uses a compression algorithm called Asymmetric Numeral Systems, which is an important part of <code>zstd</code> as well. This looks promising for a future GPU implementation of <code>zstd</code>.</p>
<p>In the future it will be interesting to benchmark other hardware accelerated compression engines, like Intel Quick Assist that will be available in the upcoming Intel Sapphire Rapids Xeon CPUs.</p>
<p>Our fork of lzbench<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a> and the code used to generate the plots<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a> are available on github.</p>
<h2 id="references">References</h2>
<!--
| Name | Device | Code |
|:-----|:-------|:-------|
| `bsc` | GPU | <https://github.com/IlyaGrebnov/libbsc> |
| `dietgpu` | GPU | <https://github.com/facebookresearch/dietgpu> |
| `libnxz` | IBM NX | <https://github.com/libnxz/power-gzip> |
| `lz4` | CPU | <https://github.com/lz4/lz4> |
| `lzma` | CPU | <https://www.7-zip.org/> |
| `nvcomp_lz4` | GPU | <https://github.com/NVIDIA/nvcomp> |
| `zlib` | CPU | <http://zlib.net/> |
| `zstd` | CPU | <https://github.com/facebook/zstd> |
-->
<!--
| Name | Device | Code |
|:-----|:-------|:-------|
| `bsc` | GPU | <https://github.com/IlyaGrebnov/libbsc> |
| `culzss` | GPU | <https://github.com/adnanozsoy/CUDA_Compression> |
| `dietgpu` | GPU | <https://github.com/facebookresearch/dietgpu> |
| `hcmc` | GPU | <https://github.com/smadhiv/HuffmanCoding_MPI_CUDA> |
| `libnxz` | IBM NX | <https://github.com/libnxz/power-gzip> |
| `lz4` | CPU | <https://github.com/lz4/lz4> |
| `lzma` | CPU | <https://www.7-zip.org/> |
| `nvcomp_lz4` | GPU | <https://github.com/NVIDIA/nvcomp> |
| `xz` | CPU | <https://tukaani.org/xz/> |
| `zlib` | CPU | <http://zlib.net/> |
| `zstd` | CPU | <https://github.com/facebook/zstd> |
-->
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p><strong>lzbench</strong><br />
An in-memory benchmark of open-source LZ77/LZSS/LZMA compressors<br />
<a href="https://github.com/inikep/lzbench" class="uri">https://github.com/inikep/lzbench</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p><strong>AMD EPYC 75F3</strong><br />
<a href="https://www.amd.com/en/product/10931" class="uri">https://www.amd.com/en/product/10931</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p><strong>NVIDIA T4</strong><br />
<a href="https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/technologies/turing-architecture/NVIDIA-Turing-Architecture-Whitepaper.pdf" class="uri">https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/technologies/turing-architecture/NVIDIA-Turing-Architecture-Whitepaper.pdf</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p><strong>IBM POWER9</strong><br />
<a href="https://www.ibm.com/common/ssi/ShowDoc.wss?docURL=/common/ssi/rep_sm/5/872/ENUS8335-_h05/index.html" class="uri">https://www.ibm.com/common/ssi/ShowDoc.wss?docURL=/common/ssi/rep_sm/5/872/ENUS8335-_h05/index.html</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p><strong>NVIDIA V100</strong><br />
<a href="https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf" class="uri">https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p><strong>LZ4</strong><br />
An algorithm based on LZ77 that prioritizes speed<br />
<a href="https://en.wikipedia.org/wiki/LZ4_(compression_algorithm)" class="uri">https://en.wikipedia.org/wiki/LZ4_(compression_algorithm)</a><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p><strong>zlib</strong><br />
A compression library that implements the DEFLATE algorithm<br />
<a href="https://en.wikipedia.org/wiki/Zlib" class="uri">https://en.wikipedia.org/wiki/Zlib</a><a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p><strong>LZMA</strong><br />
The Lempel–Ziv–Markov chain algorithm<br />
<a href="https://en.wikipedia.org/wiki/Lempel-Ziv-Markov_chain_algorithm" class="uri">https://en.wikipedia.org/wiki/Lempel-Ziv-Markov_chain_algorithm</a><a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p><strong>Zstandard</strong><br />
A compressor that combines ANS and LZ77<br />
<a href="https://en.wikipedia.org/wiki/Zstd" class="uri">https://en.wikipedia.org/wiki/Zstd</a><a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p><strong>Asymmetric numeral systems</strong><br />
Entropy coding combining speed of Huffman coding with compression rate of arithmetic coding<br />
<a href="https://arxiv.org/pdf/1311.2540.pdf" class="uri">https://arxiv.org/pdf/1311.2540.pdf</a><a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" role="doc-endnote"><p><strong>libbsc</strong><br />
A program and a library for lossless, block-sorting data compression<br />
<a href="https://github.com/IlyaGrebnov/libbsc" class="uri">https://github.com/IlyaGrebnov/libbsc</a><a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12" role="doc-endnote"><p><strong>DietGPU</strong><br />
GPU-based lossless compression for numerical data<br />
<a href="https://github.com/facebookresearch/dietgpu" class="uri">https://github.com/facebookresearch/dietgpu</a><a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13" role="doc-endnote"><p><strong>Asymmetric numeral systems</strong><br />
Entropy coding combining speed of Huffman coding with compression rate of arithmetic coding<br />
<a href="https://arxiv.org/pdf/1311.2540.pdf" class="uri">https://arxiv.org/pdf/1311.2540.pdf</a><a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14" role="doc-endnote"><p><strong>nvcomp</strong><br />
Data Compression Using NVIDIA GPUs<br />
<a href="https://developer.nvidia.com/nvcomp" class="uri">https://developer.nvidia.com/nvcomp</a><a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15" role="doc-endnote"><p><strong>libnxz</strong><br />
A zlib-compatible API for Linux userspace programs that exploit the NX GZIP accelerator available on POWER9 processors<br />
<a href="https://github.com/libnxz/power-gzip" class="uri">https://github.com/libnxz/power-gzip</a><a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16" role="doc-endnote"><p><strong>Our fork of lzbench</strong><br />
<a href="https://github.com/stefanrua/lzbench" class="uri">https://github.com/stefanrua/lzbench</a><a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17" role="doc-endnote"><p><strong>gpucomp</strong><br />
Code for generating plots and this poster<br />
<a href="https://github.com/stefanrua/gpucomp" class="uri">https://github.com/stefanrua/gpucomp</a><a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
